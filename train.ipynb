{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f73b162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import medmnist\n",
    "from medmnist import INFO\n",
    "from tqdm import tqdm\n",
    "from cnn import CNN\n",
    "from resnet import ResNet18\n",
    "from vit import VisionTransformer\n",
    "from training_evalutation_utils import * \n",
    "from plotting import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "243d9c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c04dc0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: tissuemnist\n",
      "Task: multi-class\n",
      "Input channels: 1\n",
      "Number of classes: 8\n",
      "Classes: {'0': 'Collecting Duct, Connecting Tubule', '1': 'Distal Convoluted Tubule', '2': 'Glomerular endothelial cells', '3': 'Interstitial endothelial cells', '4': 'Leukocytes', '5': 'Podocytes', '6': 'Proximal Tubule Segments', '7': 'Thick Ascending Limb'}\n"
     ]
    }
   ],
   "source": [
    "# Dataset configuration\n",
    "data_flag = 'tissuemnist'\n",
    "info = INFO[data_flag]\n",
    "task = info['task']\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])\n",
    "class_names = list(info['label'].values())\n",
    "\n",
    "print(f\"\\nDataset: {data_flag}\")\n",
    "print(f\"Task: {task}\")\n",
    "print(f\"Input channels: {n_channels}\")\n",
    "print(f\"Number of classes: {n_classes}\")\n",
    "print(f\"Classes: {info['label']}\")\n",
    "\n",
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "\n",
    "# Data transformations for models trained from scratch\n",
    "transform_scratch = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# Data transformations for transfer learning (ViT expects 3 channels and specific normalization)\n",
    "transform_transfer = T.Compose([\n",
    "    T.Grayscale(num_output_channels=3),\n",
    "    T.Resize(224),  # ViT expects 224x224 images\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet stats\n",
    "])\n",
    "\n",
    "# Load datasets for scratch models\n",
    "train_dataset_scratch = DataClass(split='train', transform=transform_scratch, download=True, size=64)\n",
    "val_dataset_scratch = DataClass(split='val', transform=transform_scratch, download=True, size=64)\n",
    "test_dataset_scratch = DataClass(split='test', transform=transform_scratch, download=True, size=64)\n",
    "\n",
    "# Load datasets for transfer learning\n",
    "train_dataset_transfer = DataClass(split='train', transform=transform_transfer, download=True, size=64)\n",
    "val_dataset_transfer = DataClass(split='val', transform=transform_transfer, download=True, size=64)\n",
    "test_dataset_transfer = DataClass(split='test', transform=transform_transfer, download=True, size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca480ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training samples: 165466\n",
      "Validation samples: 23640\n",
      "Test samples: 47280\n"
     ]
    }
   ],
   "source": [
    "# Create data loaders\n",
    "batch_size = 32\n",
    "\n",
    "train_loader_scratch = DataLoader(train_dataset_scratch, batch_size=batch_size, shuffle=True)\n",
    "val_loader_scratch = DataLoader(val_dataset_scratch, batch_size=batch_size, shuffle=False)\n",
    "test_loader_scratch = DataLoader(test_dataset_scratch, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_loader_transfer = DataLoader(train_dataset_transfer, batch_size=batch_size, shuffle=True)\n",
    "val_loader_transfer = DataLoader(val_dataset_transfer, batch_size=batch_size, shuffle=False)\n",
    "test_loader_transfer = DataLoader(test_dataset_transfer, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"\\nTraining samples: {len(train_dataset_scratch)}\")\n",
    "print(f\"Validation samples: {len(val_dataset_scratch)}\")\n",
    "print(f\"Test samples: {len(test_dataset_scratch)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679e3359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "epochs = 50\n",
    "learning_rate = 0.0001\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e73966",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 1: TRAINING FROM SCRATCH\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ---------------------- Custom CNN ----------------------\n",
    "print(\"\\n### Model 1: Custom CNN ###\")\n",
    "\n",
    "cnn_model = CNN(in_channels=1, hidden_units1=128, hidden_units2=256, output_shape=n_classes).to(device)\n",
    "cnn_optimizer = torch.optim.AdamW(cnn_model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "train_losses_cnn, val_losses_cnn, val_accs_cnn = fit(\n",
    "    cnn_model, train_loader_scratch, val_loader_scratch,\n",
    "    criterion, cnn_optimizer, epochs, device,\n",
    "    early_stopping=True, patience=5, model_name=\"cnn\",\n",
    "    save_best=True, checkpoint_path=\"cnn_best.pth\",\n",
    "    use_mixed_precision=True\n",
    ")\n",
    "\n",
    "# Evaluate CNN\n",
    "cnn_acc, cnn_preds, cnn_labels, cnn_probs = evaluate(cnn_model, test_loader_scratch, device)\n",
    "print(f\"\\n✓ Custom CNN Test Accuracy: {cnn_acc:.4f}\")\n",
    "plot_training_history(train_losses_cnn, val_losses_cnn, val_accs_cnn, \"Custom CNN\")\n",
    "plot_confusion_matrix(cnn_labels, cnn_preds, class_names, \"Custom CNN\")\n",
    "cnn_auc = plot_roc_curves(cnn_labels, cnn_probs, n_classes, class_names, \"Custom CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23c95af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- ResNet-18 ----------------------\n",
    "print(\"\\n### Model 2: ResNet-18 ###\")\n",
    "resnet_model = ResNet18(in_channels=1, num_classes=n_classes).to(device)\n",
    "resnet_optimizer = torch.optim.AdamW(resnet_model.parameters(), lr=learning_rate, \n",
    "                                     weight_decay=1e-3, amsgrad=True)\n",
    "\n",
    "train_losses_resnet, val_losses_resnet, val_accs_resnet = fit(\n",
    "    resnet_model, train_loader_scratch, val_loader_scratch,\n",
    "    criterion, resnet_optimizer, epochs, device,\n",
    "    early_stopping=True, patience=5, model_name=\"ResNet18\",\n",
    "    save_best=True, checkpoint_path=\"resnet18_best.pth\",\n",
    "    use_mixed_precision=True\n",
    ")\n",
    "\n",
    "# Evaluate ResNet\n",
    "resnet_acc, resnet_preds, resnet_labels, resnet_probs = evaluate(resnet_model, test_loader_scratch, device)\n",
    "print(f\"\\n✓ ResNet-18 Test Accuracy: {resnet_acc:.4f}\")\n",
    "\n",
    "plot_training_history(train_losses_resnet, val_losses_resnet, val_accs_resnet, \"ResNet-18\")\n",
    "plot_confusion_matrix(resnet_labels, resnet_preds, class_names, \"ResNet-18\")\n",
    "resnet_auc = plot_roc_curves(resnet_labels, resnet_probs, n_classes, class_names, \"ResNet-18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66661bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- ViT ----------------------\n",
    "print(\"\\n### Model 3: ViT ###\")\n",
    "vit = VisionTransformer(img_size=64,\n",
    "                        patch_size=8,\n",
    "                        in_ch=1,\n",
    "                        num_classes=8,\n",
    "                        embed_dim=256,\n",
    "                        depth=8,\n",
    "                        num_heads=8,\n",
    "                        mlp_ratio=4.0,\n",
    "                        dropout=0.25).to(device)\n",
    "vit_optimizer = torch.optim.AdamW(vit.parameters(), lr=learning_rate, \n",
    "                                     weight_decay=1e-2, amsgrad=True)\n",
    "\n",
    "\n",
    "train_losses_vit, val_losses_vit, val_accs_vit = fit(\n",
    "    vit, train_loader_scratch, val_loader_scratch,\n",
    "    criterion, vit_optimizer, epochs, device,\n",
    "    early_stopping=True, patience=5, model_name=\"ViT\",\n",
    "    save_best=True, checkpoint_path=\"ViT_best.pth\",\n",
    "    use_mixed_precision=True\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
